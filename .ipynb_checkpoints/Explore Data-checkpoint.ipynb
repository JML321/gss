{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed0b814-d677-4b18-9bd1-d16988997b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas sas7bdat pyreadstat\n",
    "import pandas as pd\n",
    "import sas7bdat, signal, pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7ed41a6-4f13-47bb-bbe2-23a61f86ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given file_path that has keyword per line, convert to list - remove empty lines\n",
    "def read_file_lines(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.strip() for line in lines if line.strip()]\n",
    "    return lines\n",
    "\n",
    "# get data so question columns just become row with id_vars, then columns, and total answers for question, id_vars\n",
    "def process_survey_data(df, id_vars, exclude_columns=[], include_columns=[], year=None):\n",
    "    # Filter out excluded columns if specified\n",
    "    if exclude_columns:\n",
    "        df = df.drop(columns=exclude_columns, errors='ignore')\n",
    "\n",
    "    # If include_columns is specified, reduce the dataframe to these columns only, plus id_vars\n",
    "    if include_columns:\n",
    "        columns_to_keep = id_vars + include_columns\n",
    "        df = df[columns_to_keep]\n",
    "\n",
    "    # Filter by year if the year parameter is set and 'YEAR' is one of the id_vars\n",
    "    if year is not None and 'YEAR' in id_vars:\n",
    "        df = df[df['YEAR'] >= year]\n",
    "\n",
    "    # Melting the dataframe to long format\n",
    "    d_melted = df.melt(id_vars=id_vars, var_name='Question', value_name='Answer')\n",
    "    d_melted['Answer'] = pd.to_numeric(d_melted['Answer'], errors='coerce')\n",
    "    d_melted = d_melted[d_melted['Answer'] > 0]\n",
    "\n",
    "    # Aggregating data for counting positive answers\n",
    "    question_answer_count = d_melted.groupby(id_vars + ['Question', 'Answer']).size().reset_index(name='Count')\n",
    "    question_total = d_melted.groupby(id_vars + ['Question']).size().reset_index(name='Total')\n",
    "    \n",
    "    # Aggregating total positive answers per question and year\n",
    "    num_answers_per_question = d_melted.groupby(id_vars + ['Question'])['Answer'].count().reset_index(name='Num_Answers')\n",
    "\n",
    "    # Calculating percentages\n",
    "    merged_data = pd.merge(question_answer_count, question_total, on=id_vars + ['Question'])\n",
    "    merged_data['Percentage'] = (merged_data['Count'] / merged_data['Total']) * 100\n",
    "\n",
    "    # Merging to include Num_Answers\n",
    "    final_table = pd.merge(merged_data, num_answers_per_question, on=id_vars + ['Question'])\n",
    "    final_table = final_table[id_vars + ['Question', 'Answer', 'Percentage', 'Num_Answers']]\n",
    "\n",
    "    return final_table\n",
    "\n",
    "# filter rows by number of possible answers and what year\n",
    "def filter_by_answers_and_year(df, min_answers=1000, year=1972):\n",
    "    # Filter by year\n",
    "    df_filtered = df[df['YEAR'] >= year]\n",
    "    # Filter rows where Num_Answers is less than the specified minimum\n",
    "    df_filtered = df_filtered[df_filtered['Num_Answers'] >= min_answers]\n",
    "    return df_filtered\n",
    "\n",
    "# filter by unique positive answers\n",
    "def filter_by_unique_positive_answers(df, max_unique_positives=7):\n",
    "    # Filter the dataframe to include only positive answers\n",
    "    positive_answers = df[df['Answer'] > 0]\n",
    "    unique_positives_count = positive_answers.groupby(['YEAR', 'Question'])['Answer'].nunique().reset_index()\n",
    "    valid_combinations = unique_positives_count[unique_positives_count['Answer'] <= max_unique_positives]\n",
    "    df_filtered = pd.merge(df, valid_combinations, on=['YEAR', 'Question'], how='inner')\n",
    "    df_filtered = df_filtered.drop(columns=[col for col in df_filtered if col.endswith('_y')], errors='ignore')\n",
    "    df_filtered = df_filtered.rename(columns={'Answer_x': 'Answer'})\n",
    "    return df_filtered\n",
    "\n",
    "def format_percentage_column(df):\n",
    "    # Check if 'Percentage' column exists in the DataFrame\n",
    "    if 'Percentage' not in df.columns:\n",
    "        raise ValueError(\"The DataFrame does not have a 'Percentage' column.\")\n",
    "    \n",
    "    # Function to format percentage values\n",
    "    def format_percentage(value):\n",
    "        return f\"{value / 100:.0%}\"\n",
    "    \n",
    "    # Convert 'Percentage' column to formatted percentage values\n",
    "    df['Percentage'] = df['Percentage'].apply(format_percentage)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# compare years to see which answers changed the most\n",
    "def compare_years_delta(df, year1, year2):\n",
    "    # Convert 'YEAR' to float if it's not already\n",
    "    df['YEAR'] = pd.to_numeric(df['YEAR'], errors='coerce')\n",
    "\n",
    "    # Filter data for the two years\n",
    "    df_year1 = df[df['YEAR'] == year1].copy()\n",
    "    df_year2 = df[df['YEAR'] == year2].copy()\n",
    "\n",
    "    if df_year1.empty or df_year2.empty:\n",
    "        raise ValueError(\"One of the years specified does not contain any data.\")\n",
    "\n",
    "    # Ensure the percentage columns are floats and modify data directly using .loc\n",
    "    df_year1.loc[:, 'Percentage'] = pd.to_numeric(df_year1['Percentage'], errors='coerce')\n",
    "    df_year2.loc[:, 'Percentage'] = pd.to_numeric(df_year2['Percentage'], errors='coerce')\n",
    "\n",
    "    # Rename columns for clarity after merge\n",
    "    df_year1.rename(columns={'Percentage': f'{year1} Percentage'}, inplace=True)\n",
    "    df_year2.rename(columns={'Percentage': f'{year2} Percentage'}, inplace=True)\n",
    "\n",
    "    # Merge the two years' data based on Question and Answer\n",
    "    merged_df = pd.merge(df_year1[['Question', 'Answer', f'{year1} Percentage']],\n",
    "                         df_year2[['Question', 'Answer', f'{year2} Percentage']],\n",
    "                         on=['Question', 'Answer'],\n",
    "                         how='inner')\n",
    "\n",
    "    if merged_df.empty:\n",
    "        raise ValueError(\"No common Question and Answer pairs found between the two years.\")\n",
    "\n",
    "    # Calculate the delta in percentages\n",
    "    merged_df[f'{year2}-{year1} Delta'] = merged_df[f'{year2} Percentage'] - merged_df[f'{year1} Percentage']\n",
    "\n",
    "    # Sort by delta to get the highest changes at the top\n",
    "    result_df = merged_df.sort_values(by=f'{year2}-{year1} Delta', ascending=False)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0744f5f1-c28f-4087-8a0f-283b1f5475f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\justi\\Dropbox\\Work\\Job Search\\Other\\GSS\\GSS_sas\\gss7222_r3.sas7bdat'\n",
    "df, meta = pyreadstat.read_sas7bdat(data_path)\n",
    "s = \"ATTEND CHLDIDEL CONEDUC CONLEGIS CONMEDIC IF20WHO MARBLK MEOVRWRK NATCHLD NATFAREY NATRACE NATRACEY NATROAD PARTYID POLABUSE POLATTAK POLMURDR SOCBAR SPKRAC VOTE16 VOTE20 WORDSUM XMARSEX ABANY ABPOOR ABRAPE ADULTS CONARMY FAMDIF16 FEFAM FEJOBAFF FEPRESCH IF16WHO NATCITYY NATCRIMY NATHEAL NATSPACY NEWS PILLOK PRAY REBORN RELPERSN SAVESOUL SUICIDE1 ABDEFECT ABHLTH ABNOMORE ABSINGLE CAPPUN CHILDS COLATH COLRAC COMPUSE CONBUS CONCLERG CONFED CONFINAN CONJUDGE CONLABOR CONPRESS CONSCI CONTV DISCAFF DIVORCE DWELOWN EARNRS EQWLTH EVWORK FAMILY16 FEAR FECHLD FINALTER FINRELA GOD GUNLAW HAPCOHAB HAPPY HEALTH HELPBLK HELPPOOR HELPSICK HOMOSEX INCOM16 JOBFIND LETDIE1 LETIN1A LIBATH LIBCOM LIFE MARHOMO NATAID NATAIDY NATARMS NATARMSY NATCITY NATCRIME NATDRUG NATDRUGY NATEDUC NATEDUCY NATENRGY NATENVIR NATENVIY NATFARE NATHEALY NATMASS NATPARK NATSCI NATSOC NATSPAC OTHLANG OWNGUN PARSOL PISTOL POLESCAP POLHITOK POLVIEWS PORNLAW POSSLQ POSSLQY PREMARSX PRES16 PRES20 RACDIF1 RACDIF1Y RACDIF2 RACDIF3 RACDIF4 RACEACS1 RACEACS2 RACEACS3 RACEACS4 RACEACS5 RACEACS6 RACEACS7 RACEACS15 RACEACS16 RACLIVE RACWORK RANK REG16 RELPERSN RES16 RICHWORK RIFLE ROWNGUN SATFIN SATJOB SEXEDUC SHOTGUN SOCFREND SOCOMMUN SOCREL SPANKING SPKATH SPKLANG SUICIDE4 TEENSEX UNEMP WIDOWED WRKSLF WRKSTAT WRKWAYUP\"\n",
    "key_trends=sorted(s.split())\n",
    "paradata_keywords = read_file_lines(r\"C:\\Users\\justi\\Dropbox\\Work\\Job Search\\Other\\GSS\\GSS_sas\\Paradata_variables.txt\")\n",
    "# df is the original data - each column header is a question, each row is respondents answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a963efc5-6103-465b-b077-88fd99590116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df; id_vars=['YEAR']; exclude_columns=['ID']+(paradata_keywords); include_columns=[]\n",
    "year = 2000\n",
    "# id_vars (YEAR), Question, Answer, Percentage, Num_Answers\n",
    "melted_table = process_survey_data(df, id_vars=id_vars, exclude_columns=exclude_columns, include_columns=[], year=year)\n",
    "# melted_table modified\n",
    "table = filter_by_unique_positive_answers(melted_table, max_unique_positives=7)\n",
    "table = filter_by_answers_and_year(table, min_answers=1000)\n",
    "# table = format_percentage_column(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcbc3173-f092-4ced-803b-3955e3a62052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'RATETONE', 'WHOELSE1', 'WHOELSE2', 'WHOELSE2', 'WHOELSE3', 'WHOELSE4', 'WHOELSE5', 'WHOELSE6', 'FEEUSED', 'FEELEVEL', 'MODE', 'CONSENT', 'ADMINCONSENT', 'BALLOT', 'ISSP', 'FORMWT', 'SAMPLE', 'OVERSAMP', 'SPANENG', 'HLTHSTRT', 'HUADD', 'HUADDWHY', 'DWELLPRE', 'KIDSINHH', 'RESPOND', 'INCUSPOP', 'NEISAFE', 'RLOOKS', 'RGROOMED', 'RHLTHEND', 'WTSS', 'SVYENJOY', 'SVYID1', 'SVYID2', 'MODESEQUENCE', 'TOTALINCENTIVE']\n"
     ]
    }
   ],
   "source": [
    "# table.head()\n",
    "print(exclude_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69b412ab-d37d-4470-9218-f9eb39a993b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Question  Answer  2012 Percentage  2022 Percentage  2022-2012 Delta\n",
      "460     PHONE     6.0        42.097264        69.413093        27.315828\n",
      "424      NEWS     5.0        23.520369        50.359408        26.839039\n",
      "199     GRASS     1.0        47.487844        70.169190        22.681345\n",
      "133   EVSTRAY     3.0        28.554642        51.090487        22.535846\n",
      "73   CONJUDGE     3.0        16.756757        38.418565        21.661808\n",
      "177      FUND     3.0        32.309322        52.490421        20.181099\n",
      "507   RACDIF1     1.0        35.657051        54.875887        19.218835\n",
      "514   RACDIF4     2.0        50.000000        68.845121        18.845121\n",
      "300  KIDNOFRE     3.0        11.489699        29.707495        18.217797\n",
      "110    DIVLAW     1.0        35.761589        53.723404        17.961815\n",
      "633  SSFCHILD     1.0        10.081301        26.989936        16.908635\n",
      "263  HOUSEWRK     3.0        17.483660        34.222631        16.738971\n",
      "638  SSMCHILD     1.0         9.446254        26.170799        16.724545\n",
      "399   NATCHLD     1.0        48.954895        65.631409        16.676514\n",
      "260   HOMOSEX     4.0        44.632768        61.227212        16.594444\n",
      "458     PHONE     1.0         0.557244        16.788939        16.231695\n",
      "8      ABPOOR     1.0        44.274194        60.390764        16.116570\n",
      "12   ABSINGLE     1.0        42.776886        58.781995        16.005109\n",
      "6    ABNOMORE     1.0        46.308186        60.962567        14.654381\n",
      "222   HELPBLK     1.0         7.254290        21.813403        14.559113\n",
      "0       ABANY     1.0        44.391026        58.890845        14.499819\n",
      "473  POLESCAP     2.0        25.783699        40.137812        14.354113\n",
      "157     FEFAM     4.0        19.377432        33.006814        13.629382\n",
      "270  HUBBYWK1     5.0        17.854346        31.338028        13.483682\n",
      "461    PILLOK     1.0        23.640662        36.921098        13.280436\n",
      "33    COHABOK     1.0        10.078740        23.282783        13.204043\n",
      "506  PREMARSX     4.0        56.095618        69.148021        13.052403\n",
      "393  MEOVRWRK     3.0        13.168087        26.208651        13.040565\n",
      "744  WRKWAYUP     5.0         6.577917        18.808912        12.230995\n",
      "648  SUICIDE1     1.0        59.029435        71.251109        12.221674\n",
      "660       TAX     1.0        50.157729        62.263320        12.105591\n",
      "240  HELPPOOR     1.0        16.383308        28.079242        11.695934\n",
      "45     COLRAC     5.0        51.965409        63.453990        11.488582\n",
      "377  MARLEGIT     3.0        17.845912        29.279279        11.433367\n",
      "256   HOMEKID     5.0         9.724473        21.157324        11.432850\n",
      "245  HELPSICK     1.0        29.606785        40.852346        11.245561\n",
      "332  LIVEBLKS     1.0         9.204368        20.441989        11.237621\n",
      "471  POLATTAK     2.0        11.948250        22.789116        10.840866\n",
      "501    PRAYER     1.0        40.702314        51.531059        10.828744\n",
      "666   TEENSEX     4.0         5.689790        16.516517        10.826727\n",
      "305  KIDSOCST     3.0        30.528846        41.296296        10.767450\n",
      "67     CONFED     3.0        37.719969        48.283262        10.563292\n",
      "540  RELPERSN     4.0        19.569672        29.994292        10.424620\n",
      "382    MARWHT     3.0        45.447531        55.818874        10.371343\n",
      "459     PHONE     2.0         3.495441        13.797968        10.302528\n",
      "147  FAMSUFFR     5.0        19.654088        29.805996        10.151908\n",
      "59   CONCLERG     3.0        25.136187        35.255854        10.119668\n",
      "436      OBEY     5.0        15.873016        25.893636        10.020620\n",
      "411   NATROAD     1.0        44.114583        54.042431         9.927848\n",
      "511   RACDIF3     1.0        43.705463        53.615520         9.910057\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "final_table = compare_years_delta(table, 2012, 2022)\n",
    "print(final_table.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d700bf32-04d5-4624-92a1-db2491f01952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ca9ef34-8cd4-4cd7-943f-78ba1e86755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_codebook(file_path):\n",
    "    import re\n",
    "\n",
    "    # Regular expressions to capture required parts\n",
    "    variable_pattern = re.compile(r'Variable:\\s+(\\S+)\\s+Type:', re.IGNORECASE)\n",
    "    label_pattern = re.compile(r'Label:\\s*(.*?)\\s*Notes:', re.IGNORECASE | re.DOTALL)\n",
    "    answer_pattern = re.compile(r'LABEL VALUE COUNT PCT\\s*PCT Excl\\.\\s*Reserve\\s*Codes\\s*((?:\\n.+)+)', re.IGNORECASE)\n",
    "\n",
    "    # Dictionaries to hold the results\n",
    "    labels_dict = {}\n",
    "    answer_keys_dict = {}\n",
    "\n",
    "    # Read the file content\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Split content into sections based on variables\n",
    "    sections = re.split(r'\\n(?=Variable:)', content, flags=re.IGNORECASE)\n",
    "\n",
    "    for section in sections:\n",
    "        # Search for the variable name\n",
    "        variable_match = variable_pattern.search(section)\n",
    "        if variable_match:\n",
    "            variable = variable_match.group(1)\n",
    "\n",
    "            # Search for the label\n",
    "            label_match = label_pattern.search(section)\n",
    "            if label_match:\n",
    "                label = label_match.group(1).strip()\n",
    "                labels_dict[variable] = label\n",
    "\n",
    "            # Search for the answer keys\n",
    "            answer_match = answer_pattern.search(section)\n",
    "            if answer_match:\n",
    "                answer_text = answer_match.group(1).strip()\n",
    "                answer_lines = answer_text.split('\\n')\n",
    "                answer_dict = {}\n",
    "                for line in answer_lines:\n",
    "                    # Match the pattern: \"VERY LIKELY 1 424 12.0% 12.4%\"\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        value = parts[0]\n",
    "                        key = parts[1]\n",
    "                        if key.isdigit():  # Ensure that it's a valid answer key\n",
    "                            answer_dict[key] = value\n",
    "\n",
    "                answer_keys_dict[variable] = answer_dict\n",
    "\n",
    "    return labels_dict, answer_keys_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e49c9031-b2ed-43ba-b5c4-a13c27f80609",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mjusti\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGSS-2022-Codebook.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m labels_d, answer_keys_d \u001b[38;5;241m=\u001b[39m \u001b[43mparse_codebook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 43\u001b[0m, in \u001b[0;36mparse_codebook\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parts:\n\u001b[0;32m     42\u001b[0m     value \u001b[38;5;241m=\u001b[39m parts[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 43\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mparts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39misdigit():  \u001b[38;5;66;03m# Ensure that it's a valid answer key\u001b[39;00m\n\u001b[0;32m     45\u001b[0m         answer_dict[key] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\justi\\Downloads\\GSS-2022-Codebook.txt\"\n",
    "labels_d, answer_keys_d = parse_codebook(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4992a-b9f1-4c91-b7d9-47b80e87fc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
